{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data from trainingData.csv and trainingLabels.csv\n",
    "colnames_train = ['session_id', 'start_time', 'end_time', 'product_list']\n",
    "colnames_test = ['label']\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%dT%H:%M:%S')\n",
    "df = pd.read_csv(\"./data/trainingData.csv\", names=colnames_train, parse_dates=['start_time', 'end_time'], header=None)\n",
    "df_test = pd.read_csv(\"./data/trainingLabels.csv\", names = colnames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature_Engineering\n",
    "df['session_duration'] = (df['end_time'] - df['start_time']).dt.total_seconds()\n",
    "df['product_count'] = df['product_list'].str.count('A')\n",
    "df['Average_duration_per_product'] = df['session_duration'] / df['product_count']\n",
    "df['day_of_week'] = df['end_time'].dt.dayofweek\n",
    "df['date'] = df['end_time'].dt.day\n",
    "df['month'] = df['end_time'].dt.month\n",
    "df['start_hour'] = df['start_time'].dt.hour\n",
    "df['end_hour'] = df['end_time'].dt.hour\n",
    "\n",
    "#Scaling the product_count variable\n",
    "sc = StandardScaler()\n",
    "prd_cnt = np.array(df['product_count'])\n",
    "prd_cnt = prd_cnt.reshape(-1, 1)\n",
    "df['product_count'] = sc.fit_transform(prd_cnt)\n",
    "df_dummy = df.iloc[:,7:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy encoding the categorical data such as day_of_week, date, month, start_hour, end_hour\n",
    "dummy = pd.get_dummies(df_dummy, columns=['day_of_week', 'date', 'month', 'start_hour', 'end_hour'])\n",
    "df = pd.concat([df, dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data for identifying the number of nodes at each level/hierarchy\n",
    "df['product_list'] = df.product_list.apply(lambda x: x.split('/'))\n",
    "df['product_list'] = df.product_list.apply(' '.join).str.replace('[^A-Za-z0-9,\\s]+', '').str.split(expand=False)\n",
    "df['new'] = df['product_list'].map(set)\n",
    "df['new'] = df['new'].apply(lambda x: ','.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating number of nodes at each level\n",
    "df['A_unique_count'] = df['new'].str.count('A')\n",
    "df['B_unique_count'] = df['new'].str.count('B')\n",
    "df['C_unique_count'] = df['new'].str.count('C')\n",
    "df['D_unique_count'] = df['new'].str.count('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the varibles which have been dummy-encoded\n",
    "df.drop(['day_of_week', 'date', 'month', 'start_hour', 'end_hour', 'new'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session_id', 'start_time', 'end_time', 'product_list',\n",
       "       'session_duration', 'product_count', 'Average_duration_per_product',\n",
       "       'day_of_week_0', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3',\n",
       "       'day_of_week_4', 'day_of_week_5', 'day_of_week_6', 'date_1', 'date_2',\n",
       "       'date_3', 'date_5', 'date_6', 'date_7', 'date_8', 'date_9', 'date_12',\n",
       "       'date_13', 'date_14', 'date_15', 'date_16', 'date_17', 'date_18',\n",
       "       'date_19', 'date_20', 'date_21', 'date_22', 'date_23', 'date_25',\n",
       "       'date_26', 'date_27', 'date_28', 'date_29', 'date_30', 'month_11',\n",
       "       'month_12', 'start_hour_0', 'start_hour_1', 'start_hour_2',\n",
       "       'start_hour_3', 'start_hour_4', 'start_hour_5', 'start_hour_6',\n",
       "       'start_hour_7', 'start_hour_8', 'start_hour_9', 'start_hour_10',\n",
       "       'start_hour_11', 'start_hour_12', 'start_hour_13', 'start_hour_14',\n",
       "       'start_hour_15', 'start_hour_16', 'start_hour_17', 'start_hour_18',\n",
       "       'start_hour_19', 'start_hour_20', 'start_hour_21', 'start_hour_22',\n",
       "       'start_hour_23', 'end_hour_0', 'end_hour_1', 'end_hour_2', 'end_hour_3',\n",
       "       'end_hour_4', 'end_hour_5', 'end_hour_6', 'end_hour_7', 'end_hour_8',\n",
       "       'end_hour_9', 'end_hour_10', 'end_hour_11', 'end_hour_12',\n",
       "       'end_hour_13', 'end_hour_14', 'end_hour_15', 'end_hour_16',\n",
       "       'end_hour_17', 'end_hour_18', 'end_hour_19', 'end_hour_20',\n",
       "       'end_hour_21', 'end_hour_22', 'end_hour_23', 'A_unique_count',\n",
       "       'B_unique_count', 'C_unique_count', 'D_unique_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index of columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy encoding products/hierarchical nodes using multilabel Binarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_product = pd.DataFrame(mlb.fit_transform(df['product_list']),columns=mlb.classes_, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the products/hierarchical nodes that appear less than 3 times\n",
    "df_product.drop([col for col, val in df_product.sum().iteritems() if val < 3], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining the features extracted with the dummy encoded product/hierarchical data. Dropped redundant and unwanted data for model construction.\n",
    "df_product = pd.concat([df_product, df], axis = 1)\n",
    "df_product.drop(['product_list', 'session_id', 'start_time', 'end_time'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the target variable \"gender\"\n",
    "df_product['gender'] = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting female and male class to 0 and 1 respectively\n",
    "labelencoder_y = LabelEncoder()\n",
    "df_product['gender'] = labelencoder_y.fit_transform(df_product['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "0    11703\n",
       "1     3297\n",
       "Name: day_of_week_1, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target varible - class proportion\n",
    "df_product.groupby(['gender'])['day_of_week_1'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18714, 2592)\n",
      "(18714,)\n"
     ]
    }
   ],
   "source": [
    "#Creating X - feature and y - target. Train test split - 80:20\n",
    "X = df_product.iloc[:,:-1].values\n",
    "y = df_product.iloc[:,-1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "#Oversampling using SMOTE - Synthetic minority Oversampling technique\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the algorithm(computed as given in question): 0.7983254729893553\n",
      "General accuracy: 0.8553333333333333\n",
      "confusion matrix:\n",
      " [[2110  236]\n",
      " [ 198  456]]\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.90      0.91      2346\n",
      "          1       0.66      0.70      0.68       654\n",
      "\n",
      "avg / total       0.86      0.86      0.86      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "score = ((tp/ (tp+fn)) + (tn/ (tn+fp)))/2\n",
    "print(\"Score of the algorithm(computed as given in question):\", score)\n",
    "print(\"General accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the algorithm(computed as given in question): 0.7684170596838655\n",
      "General accuracy: 0.8266666666666667\n",
      "confusion matrix:\n",
      " [[2045  301]\n",
      " [ 219  435]]\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.87      0.89      2346\n",
      "          1       0.59      0.67      0.63       654\n",
      "\n",
      "avg / total       0.84      0.83      0.83      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Neural network\n",
    "MLP_Classifier = MLPClassifier(random_state=4, learning_rate = 'invscaling', hidden_layer_sizes= (50,40,30))\n",
    "MLP_Classifier.fit(X_train,y_train)\n",
    "y_pred = MLP_Classifier.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "score = ((tp/ (tp+fn)) + (tn/ (tn+fp)))/2\n",
    "print(\"Score of the algorithm(computed as given in question):\", score)\n",
    "print(\"General accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the algorithm(computed as given in question): 0.7515407838444512\n",
      "General accuracy: 0.8416666666666667\n",
      "confusion matrix:\n",
      " [[2138  208]\n",
      " [ 267  387]]\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.91      0.90      2346\n",
      "          1       0.65      0.59      0.62       654\n",
      "\n",
      "avg / total       0.84      0.84      0.84      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Linear Support Vector classifier\n",
    "Linear_SVC = LinearSVC()\n",
    "Linear_SVC.fit(X_train,y_train)\n",
    "y_pred = Linear_SVC.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "score = ((tp/ (tp+fn)) + (tn/ (tn+fp)))/2\n",
    "print(\"Score of the algorithm(computed as given in question):\", score)\n",
    "print(\"General accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the algorithm(computed as given in question): 0.7765003089388927\n",
      "General accuracy: 0.8746666666666667\n",
      "confusion matrix:\n",
      " [[2230  116]\n",
      " [ 260  394]]\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.92      2346\n",
      "          1       0.77      0.60      0.68       654\n",
      "\n",
      "avg / total       0.87      0.87      0.87      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "GBM = GradientBoostingClassifier()\n",
    "# class_weight= {0:0.22, 1:0.78}\n",
    "GBM.fit(X_train,y_train)\n",
    "y_pred = GBM.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "score = ((tp/ (tp+fn)) + (tn/ (tn+fp)))/2\n",
    "print(\"Score of the algorithm(computed as given in question):\", score)\n",
    "print(\"General accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the algorithm(computed as given in question): 0.7853500394972508\n",
      "General accuracy: 0.8833333333333333\n",
      "confusion matrix:\n",
      " [[2250   96]\n",
      " [ 254  400]]\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93      2346\n",
      "          1       0.81      0.61      0.70       654\n",
      "\n",
      "avg / total       0.88      0.88      0.88      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "Randomforest = RandomForestClassifier(random_state= 134, n_estimators= 100)\n",
    "Randomforest.fit(X_train,y_train)\n",
    "y_pred = Randomforest.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "score = ((tp/ (tp+fn)) + (tn/ (tn+fp)))/2\n",
    "print(\"Score of the algorithm(computed as given in question):\", score)\n",
    "print(\"General accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the algorithm(computed as given in question): 0.7413849065753146\n",
      "General accuracy: 0.8223333333333334\n",
      "confusion matrix:\n",
      " [[2076  270]\n",
      " [ 263  391]]\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.88      0.89      2346\n",
      "          1       0.59      0.60      0.59       654\n",
      "\n",
      "avg / total       0.82      0.82      0.82      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "Decisiontree = DecisionTreeClassifier()\n",
    "Decisiontree.fit(X_train,y_train)\n",
    "y_pred = Decisiontree.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "score = ((tp/ (tp+fn)) + (tn/ (tn+fp)))/2\n",
    "print(\"Score of the algorithm(computed as given in question):\", score)\n",
    "print(\"General accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of the algorithm(computed as given in question): 0.7977818969630134\n",
      "General accuracy: 0.8846666666666667\n",
      "confusion matrix:\n",
      " [[2233  113]\n",
      " [ 233  421]]\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.95      0.93      2346\n",
      "          1       0.79      0.64      0.71       654\n",
      "\n",
      "avg / total       0.88      0.88      0.88      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\praveen.kumar\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "#Ensemble using Voting classifier of Decision tree, Random forest, linear support vector classifier, Neural network, Gradient Boost, Logistic regression\n",
    "ensemble = VotingClassifier(estimators = [('GBM', GBM), ('DT',Decisiontree), ('RF', Randomforest), ('SVC', Linear_SVC), ('NN', MLP_Classifier), ('LR', lr)], n_jobs=-1)\n",
    "ensemble.fit(X_train,y_train)\n",
    "y_pred = ensemble.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "score = ((tp/ (tp+fn)) + (tn/ (tn+fp)))/2\n",
    "print(\"Score of the algorithm(computed as given in question):\", score)\n",
    "print(\"General accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"classification report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
